{\rtf1\ansi\ansicpg1252\deff0\nouicompat\deflang1033{\fonttbl{\f0\fnil\fcharset0 Times New Roman;}}
{\colortbl ;\red0\green0\blue255;}
{\*\generator Riched20 10.0.19041}\viewkind4\uc1 
\pard\sa200\sl276\slmult1\b\f0\fs32\lang9 Exercise 1 - Extracting data using 'cut' command\par
\b0 The filter command cut helps us extract selected characters or fields from a line of text.\par
theia@theiadocker-rajendraabro:/home/project$ echo "database" | cut -c1-4\par
 output : data\par
theia@theiadocker-rajendraabro:/home/project$ echo "database" | cut -c5-8\par
output:base\par
theia@theiadocker-rajendraabro:/home/project$ echo "database" | cut -c1,5\par
output:db\par
Extracting fields/columns\par
We can extract a specific column/field from a delimited text file, by mentioning\par
\par
the delimiter using the -d option, or\par
the field number using the -f option.\par
The /etc/passwd is a \ldblquote :\rdblquote  delimited file.\par
\par
The command below extracts usernames (the first field) from /etc/passwd.\par
The command below extracts multiple fields 1st, 3rd, and 6th (username, userid, and home directory) from /etc/passwd.\par
theia@theiadocker-rajendraabro:/home/project$ cut -d":" -f1 /etc/passwd\par
root\par
daemon\par
bin\par
sys\par
sync\par
games\par
man\par
lp\par
mail\par
news\par
uucp\par
proxy\par
www-data\par
backup\par
list\par
irc\par
gnats\par
nobody\par
_apt\par
systemd-network\par
systemd-resolve\par
messagebus\par
systemd-timesync\par
sshd\par
theia\par
cassandra\par
mongodb\par
The command below extracts a range of fields 3rd to 6th (userid, groupid, user description and home directory) from /etc/passwd.\par
theia@theiadocker-rajendraabro:/home/project$ cut -d":" -f3-6 /etc/passwd\par
0:0:root:/root\par
1:1:daemon:/usr/sbin\par
2:2:bin:/bin\par
3:3:sys:/dev\par
4:65534:sync:/bin\par
5:60:games:/usr/games\par
6:12:man:/var/cache/man\par
7:7:lp:/var/spool/lpd\par
8:8:mail:/var/mail\par
9:9:{{\field{\*\fldinst{HYPERLINK news:/var/spool/news }}{\fldrslt{news:/var/spool/news\ul0\cf0}}}}\f0\fs32\par
10:10:uucp:/var/spool/uucp\par
13:13:proxy:/bin\par
33:33:www-data:/var/www\par
34:34:backup:/var/backups\par
38:38:Mailing List Manager:/var/list\par
39:39:ircd:/run/ircd\par
41:41:Gnats Bug-Reporting System (admin):/var/lib/gnats\par
65534:65534:nobody:/nonexistent\par
100:65534::/nonexistent\par
101:102:systemd Network Management,,,:/run/systemd\par
102:103:systemd Resolver,,,:/run/systemd\par
103:105::/nonexistent\par
104:106:systemd Time Synchronization,,,:/run/systemd\par
105:65534::/run/sshd\par
1000:1000:,,,:/home/theia\par
106:109:Cassandra database,,,:/var/lib/cassandra\par
107:65534::/home/mongodb\par
\b Exercise 2 - Transforming data using 'tr'\b0\par
tr is a filter command used to translate, squeeze, and/or delete characters.\par
\par
Translate from one character set to another\par
theia@theiadocker-rajendraabro:/home/project$ echo "Shell Scripting" | tr "[a-z]" "[A-Z]"\par
SHELL SCRIPTING\par
theia@theiadocker-rajendraabro:/home/project$ echo "Shell Scripting" | tr "[:lower:]" "[:upper:]"\par
SHELL SCRIPTING\par
theia@theiadocker-rajendraabro:/home/project$ echo "Shell Scripting" | tr  "[A-Z]" "[a-z]"\par
shell scripting\par
\b Squeeze repeating occurrences of characters\par
The -s option replaces a sequence of a repeated characters with a single occurrence of that character.\par
\par
The command below replaces repeat occurrences of \lquote space\rquote  in the output of ps command with one \lquote space\rquote .\par
\b0 theia@theiadocker-rajendraabro:/home/project$ ps | tr -s " "\par
 PID TTY TIME CMD\par
 232 pts/0 00:00:00 bash\par
 1077 pts/0 00:00:00 ps\par
 1078 pts/0 00:00:00 tr\par
\b In the above example, the space character within quotes can be replaced with the following : "[\\:space\\:]".\par
\par
Delete characters\par
We can delete specified characters using the -d  option.\par
\par
The command below deletes all digits.\par
\b0 theia@theiadocker-rajendraabro:/home/project$ echo "My login pin is 5634" | tr -d "[:digit:]"\par
My login pin is \par
\b Exercise 3 - Start the PostgreSQL database.\par
Exercise 4 - Create a table\par
In this exercise we will create a table called users in the PostgreSQL database using PostgresSQL CLI. This table will hold the user account information.\par
\par
The table users will have the following columns:\par
\par
uname\par
\par
uid\par
\par
home\par
\par
You will connect to template1 database which is already available by default. To connect to this database, run the following command at the \lquote postgres=#\rquote  prompt.\par
\b0 postgres=# \\c template1\par
psql (14.19 (Ubuntu 14.19-0ubuntu0.22.04.1), server 13.2)\par
You are now connected to database "template1" as user "postgres".\par
template1=# \par
If the table is created successfully, you will get the message below.\par
CREATE TABLE\par
template1=# create table users(username varchar(50),userid int,homedirectory varchar(100));\par
CREATE TABLE\par
template1=# \par
9ffGjtYCxAmNU3LGgjnLDhyh\b\par
Exercise 5 - Loading data into a PostgreSQL table.\par
postgreCLI to terminal\par
In the terminal, run the following command to create a new shell script named csv2db.sh.\par
\b0 theia@theiadocker-rajendraabro:/home/project$ touch csv2db.sh\par
\b You need to add lines of code to the script that will xtract user name (field 1), user id (field 3), and home directory path (field 6) from /etc/passwd file using the cut command.\par
bash csv2db.sh\par
\b0 # Extract phase\par
\par
echo "Extracting data"\par
\par
# Extract the columns 1 (user name), 2 (user id) and \par
# 6 (home directory path) from /etc/passwd\par
\par
cut -d":" -f1,3,6 /etc/passwd\par
\b theia@theiadocker-rajendraabro:/home/project$ bash csv2db.sh\par
Extracting data\par
root:0:/root\par
daemon:1:/usr/sbin\par
bin:2:/bin\par
sys:3:/dev\par
sync:4:/bin\par
games:5:/usr/games\par
man:6:/var/cache/man\par
lp:7:/var/spool/lpd\par
mail:8:/var/mail\par
{{\field{\*\fldinst{HYPERLINK news:9:/var/spool/news }}{\fldrslt{news:9:/var/spool/news\ul0\cf0}}}}\f0\fs32\par
uucp:10:/var/spool/uucp\par
proxy:13:/bin\par
www-data:33:/var/www\par
backup:34:/var/backups\par
list:38:/var/list\par
irc:39:/run/ircd\par
gnats:41:/var/lib/gnats\par
nobody:65534:/nonexistent\par
_apt:100:/nonexistent\par
systemd-network:101:/run/systemd\par
systemd-resolve:102:/run/systemd\par
messagebus:103:/nonexistent\par
systemd-timesync:104:/run/systemd\par
sshd:105:/run/sshd\par
theia:1000:/home/theia\par
cassandra:106:/var/lib/cassandra\par
mongodb:107:/home/mongodb\par
\b0 theia@theiadocker-rajendraabro:/home/project$ bash csv2db.sh\par
Extracting data\par
\fs40 # Transform phase\par
echo "Transforming data"\par
# read the extracted data and replace the colons with commas.\par
\par
tr ":" "," < extracted-data.txt  > transformed-data.csv\par
\fs32 theia@theiadocker-rajendraabro:/home/project$ cat extracted-data.txt\par
root:0:/root\par
daemon:1:/usr/sbin\par
bin:2:/bin\par
sys:3:/dev\par
sync:4:/bin\par
games:5:/usr/games\par
man:6:/var/cache/man\par
lp:7:/var/spool/lpd\par
mail:8:/var/mail\par
{{\field{\*\fldinst{HYPERLINK news:9:/var/spool/news }}{\fldrslt{news:9:/var/spool/news\ul0\cf0}}}}\f0\fs32\par
uucp:10:/var/spool/uucp\par
proxy:13:/bin\par
www-data:33:/var/www\par
backup:34:/var/backups\par
list:38:/var/list\par
irc:39:/run/ircd\par
gnats:41:/var/lib/gnats\par
nobody:65534:/nonexistent\par
_apt:100:/nonexistent\par
systemd-network:101:/run/systemd\par
systemd-resolve:102:/run/systemd\par
messagebus:103:/nonexistent\par
systemd-timesync:104:/run/systemd\par
sshd:105:/run/sshd\par
theia:1000:/home/theia\par
cassandra:106:/var/lib/cassandra\par
mongodb:107:/home/mongodb\par
The extracted columns are separated by the original \ldblquote :\rdblquote  delimiter. You need to convert this into a \ldblquote ,\rdblquote  delimited file. Add the below lines at the end of the script and save the file.\par
theia@theiadocker-rajendraabro:/home/project$ bash csv2db.sh\par
Extracting data\par
Transforming data\par
theia@theiadocker-rajendraabro:/home/project$ cat transformed-data.csv\par
root,0,/root\par
daemon,1,/usr/sbin\par
bin,2,/bin\par
sys,3,/dev\par
sync,4,/bin\par
games,5,/usr/games\par
man,6,/var/cache/man\par
lp,7,/var/spool/lpd\par
mail,8,/var/mail\par
news,9,/var/spool/news\par
uucp,10,/var/spool/uucp\par
proxy,13,/bin\par
www-data,33,/var/www\par
backup,34,/var/backups\par
list,38,/var/list\par
irc,39,/run/ircd\par
gnats,41,/var/lib/gnats\par
nobody,65534,/nonexistent\par
_apt,100,/nonexistent\par
systemd-network,101,/run/systemd\par
systemd-resolve,102,/run/systemd\par
messagebus,103,/nonexistent\par
systemd-timesync,104,/run/systemd\par
sshd,105,/run/sshd\par
theia,1000,/home/theia\par
cassandra,106,/var/lib/cassandra\par
mongodb,107,/home/mongodb\par
To load data from a shell script, you will use the psql client utility in a non-interactive manner. This is done by sending the database commands through a command pipeline to psql with the help of echo command.\par
PostgreSQL command to copy data from a CSV file to a table is COPY.\par
\par
The basic structure of the command which we will use in our script is,\par
\par
COPY table_name FROM 'filename' DELIMITERS 'delimiter_character' FORMAT;\par
\par
Now, add the lines below to the end of the script \lquote csv2db.sh\rquote  and save the file.\par
theia@theiadocker-rajendraabro:/home/project$ bash csv2db.sh\par
Extracting data\par
Transforming data\par
Loading data\par
You are now connected to database "template1" as user "postgres".\par
COPY 27\par
\fs40 # Load phase\par
echo "Loading data"\par
# Set the PostgreSQL password environment variable.\par
# Replace <yourpassword> with your actual PostgreSQL password.\par
export PGPASSWORD=<yourpassword>;\par
# Send the instructions to connect to 'template1' and\par
# copy the file to the table 'users' through command pipeline.\par
echo "\\c template1;\\COPY users  FROM '/home/project/transformed-data.csv' DELIMITERS ',' CSV;" | psql --username=postgres --host=postgres\par
\fs56 Exercise 6 - Execute the final script\fs32\par
theia@theiadocker-rajendraabro:/home/project$ bash csv2db.sh\par
Extracting data\par
Transforming data\par
Loading data\par
You are now connected to database "template1" as user "postgres".\par
COPY 27\par
     username     | userid |   homedirectory    \par
------------------+--------+--------------------\par
 root             |      0 | /root\par
 daemon           |      1 | /usr/sbin\par
 bin              |      2 | /bin\par
 sys              |      3 | /dev\par
 sync             |      4 | /bin\par
 games            |      5 | /usr/games\par
 man              |      6 | /var/cache/man\par
 lp               |      7 | /var/spool/lpd\par
 mail             |      8 | /var/mail\par
 news             |      9 | /var/spool/news\par
 uucp             |     10 | /var/spool/uucp\par
 proxy            |     13 | /bin\par
 www-data         |     33 | /var/www\par
 backup           |     34 | /var/backups\par
 list             |     38 | /var/list\par
 irc              |     39 | /run/ircd\par
 gnats            |     41 | /var/lib/gnats\par
 nobody           |  65534 | /nonexistent\par
 _apt             |    100 | /nonexistent\par
 systemd-network  |    101 | /run/systemd\par
 systemd-resolve  |    102 | /run/systemd\par
 messagebus       |    103 | /nonexistent\par
 systemd-timesync |    104 | /run/systemd\par
 sshd             |    105 | /run/sshd\par
 theia            |   1000 | /home/theia\par
 cassandra        |    106 | /var/lib/cassandra\par
 mongodb          |    107 | /home/mongodb\par
 root             |      0 | /root\par
 daemon           |      1 | /usr/sbin\par
 bin              |      2 | /bin\par
 sys              |      3 | /dev\par
 sync             |      4 | /bin\par
 games            |      5 | /usr/games\par
 man              |      6 | /var/cache/man\par
 lp               |      7 | /var/spool/lpd\par
 mail             |      8 | /var/mail\par
 news             |      9 | /var/spool/news\par
 uucp             |     10 | /var/spool/uucp\par
 proxy            |     13 | /bin\par
 www-data         |     33 | /var/www\par
 backup           |     34 | /var/backups\par
 list             |     38 | /var/list\par
 irc              |     39 | /run/ircd\par
 gnats            |     41 | /var/lib/gnats\par
 nobody           |  65534 | /nonexistent\par
 _apt             |    100 | /nonexistent\par
 systemd-network  |    101 | /run/systemd\par
 systemd-resolve  |    102 | /run/systemd\par
 messagebus       |    103 | /nonexistent\par
 systemd-timesync |    104 | /run/systemd\par
 sshd             |    105 | /run/sshd\par
 theia            |   1000 | /home/theia\par
 cassandra        |    106 | /var/lib/cassandra\par
 mongodb          |    107 | /home/mongodb\par
(54 rows)\par
Practice exercises\par
Copy the data in the file \lquote web-server-access-log.txt.gz\rquote  to the table \lquote access_log\rquote  in the PostgreSQL database \lquote template1\rquote .\par
\par
The file is available at the location : {{\field{\*\fldinst{HYPERLINK https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0250EN-SkillsNetwork/labs/Bash%20Scripting/ETL%20using%20shell%20scripting/web-server-access-log.txt.gz }}{\fldrslt{https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0250EN-SkillsNetwork/labs/Bash%20Scripting/ETL%20using%20shell%20scripting/web-server-access-log.txt.gz\ul0\cf0}}}}\f0\fs32\par
\par
The following are the columns and their data types in the file:\par
\par
a. timestamp - TIMESTAMP\par
b. latitude - float\par
c. longitude - float\par
d. visitorid - char(37)\par
e. accessed_from_mobile - boolean\par
f. browser_code - int\par
The columns which we need to copy to the table are the first four coumns : timestamp, latitude, longitude and visitorid.\par
\par
NOTE: The file comes with a header. So use the \lquote HEADER\rquote  option in the \lquote COPY\rquote  command.\par
\par
The problem may be solved by completing the following tasks:\par
\par
Go to the SkillsNetwork Tools menu and start the Postgres SQL server if it is not already running.\par
\par
Create a table named access_log to store the timestamp, latitude, longitude and visitorid.\par
\par
Click here for Hint\par
Click here for Solution\par
Step 1: Open the Postgres SQL CLI, if it is not already open.\par
\par
Step 2: At the postgres=# prompt, run the following command to connect to the database \lquote template1\rquote .\par
\par
1\par
\\c template1;\par
\par
Copied!\par
\par
Wrap Toggled!\par
Step 3: Once you connect to the database, run the command to create the table called \lquote access_log\rquote :\par
\par
1\par
CREATE TABLE access_log(timestamp TIMESTAMP, latitude float, longitude float, visitor_id char(37));\par
\par
Copied!\par
\par
Wrap Toggled!\par
Task 3. Create a shell script named cp-access-log.sh and add commands to complete the remaining tasks to extract and copy the data to the database.\par
\par
Create a shell script to add commands to complete the rest of the tasks.\par
\par
Click here for Hint\par
Task 4. Download the access log file.\par
\par
Add the wget command to the script to download the file.\par
\par
1\par
wget "{{\field{\*\fldinst{HYPERLINK https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0250EN-SkillsNetwork/labs/Bash%20Scripting/ETL%20using%20shell%20scripting/web-server-access-log.txt.gz }}{\fldrslt{https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0250EN-SkillsNetwork/labs/Bash%20Scripting/ETL%20using%20shell%20scripting/web-server-access-log.txt.gz\ul0\cf0}}}}\f0\fs32 "\par
\par
Copied!\par
\par
Wrap Toggled!\par
Task 5. Unzip the gzip file.\par
\par
Add the code, to run the gunzip command to unzip the .gz file and extract the .txt file, to the script.\par
\par
1\par
2\par
# Unzip the file to extract the .txt file.\par
gunzip -f web-server-access-log.txt.gz\par
\par
Copied!\par
\par
Wrap Toggled!\par
The -f option of gunzip is to overwrite the file if it already exists.\par
\par
Task 6. Extract required fields from the file.\par
\par
Extract timestamp, latitude, longitude and visitorid which are the first four fields from the file using the cut command.\par
\par
The columns in the web-server-access-log.txt file is delimited by \lquote #\rquote .\par
\par
Click here for Hint\par
Click here for Solution\par
Step 1: Copy the following lines and add them to the end of the script.\par
\par
1\par
2\par
3\par
4\par
5\par
6\par
7\par
8\par
# Extract phase\par
echo "Extracting data"\par
# Extract the columns 1 (timestamp), 2 (latitude), 3 (longitude) and \par
# 4 (visitorid)\par
cut -d"#" -f1-4 web-server-access-log.txt\par
\par
Copied!\par
\par
Wrap Toggled!\par
Step 2: Save the file.\par
\par
Step 3: Run the script.\par
\par
1\par
bash cp-access-log.sh\par
\par
Copied!\par
\par
Wrap Toggled!\par
\par
Executed!\par
Verify that the output contains all the four fields that we extracted.\par
\par
Task 7. Redirect the extracted output into a file.\par
\par
Redirect the extracted data into a file named extracted-data.txt\par
\par
Click here for Hint\par
Click here for Solution\par
Step 1: Replace the cut command at end of the script with the following command and save the file.\par
\par
1\par
cut -d"#" -f1-4 web-server-access-log.txt > extracted-data.txt\par
\par
Copied!\par
\par
Wrap Toggled!\par
Step 2: Run the script.\par
\par
1\par
bash cp-access-log.sh\par
\par
Copied!\par
\par
Wrap Toggled!\par
Step 3: Run the command below to verify that the file extracted-data.txt is created, and has the content.\par
\par
1\par
cat extracted-data.txt\par
\par
Copied!\par
\par
Wrap Toggled!\par
Task 8. Transform the data into CSV format.\par
\par
The extracted columns are separated by the original \ldblquote #\rdblquote  delimiter.\par
\par
We need to convert this into a \ldblquote ,\rdblquote  delimited file.\par
\par
Click here for Hint\par
Click here for Solution\par
Step 1: Add the lines below at the end of the script.\par
\par
1\par
2\par
3\par
4\par
5\par
6\par
# Transform phase\par
echo "Transforming data"\par
# read the extracted data and replace the colons with commas and\par
# write it to a csv file\par
tr "#" "," < extracted-data.txt > transformed-data.csv\par
\par
Copied!\par
\par
Wrap Toggled!\par
Step 2: Save the file.\par
\par
Step 3: Run the script.\par
\par
1\par
bash cp-access-log.sh\par
\par
Copied!\par
\par
Wrap Toggled!\par
Step 4: Run the command below to verify that the file \lquote transformed-data.csv\rquote  is created, and has the content.\par
\par
1\par
cat transformed-data.csv\par
\par
Copied!\par
\par
Wrap Toggled!\par
Task 9. Load the data into the table access_log in PostgreSQL\par
\par
PostgreSQL command to copy data from a CSV file to a table is COPY.\par
\par
The basic structure of the command is,\par
\par
1\par
COPY table_name FROM 'filename' DELIMITERS 'delimiter_character' FORMAT;\par
\par
Copied!\par
\par
Wrap Toggled!\par
The file comes with a header. So use the \lquote HEADER\rquote  option in the \lquote COPY\rquote  command.\par
\par
Invoke this command from the shellscript, by sending it as input to \lquote psql\rquote  filter command.\par
\par
Click here for Hint\par
Click here for Solution\par
Step 1: Add the lines below to the end of the script \lquote cp-access-log.sh\rquote  and save the file.\par
\par
1\par
2\par
3\par
4\par
5\par
6\par
7\par
# Load phase\par
echo "Loading data"\par
# Send the instructions to connect to 'template1' and\par
# copy the file to the table 'access_log' through command pipeline.\par
echo "\\c template1;\\COPY access_log  FROM '/home/project/transformed-data.csv' DELIMITERS ',' CSV HEADER;" | psql --username=postgres --host=localhost\par
\par
Copied!\par
\par
Wrap Toggled!\par
Task 10. Execute the final script.\par
\par
Run the final script.\par
\par
Click here for Solution\par
Run the following command at the terminal:\par
\par
1\par
bash cp-access-log.sh\par
\par
Copied!\par
\par
Wrap Toggled!\par
The completed bash script would be as below.\par
\par
1\par
2\par
3\par
4\par
5\par
6\par
7\par
8\par
9\par
10\par
11\par
12\par
13\par
14\par
15\par
16\par
17\par
18\par
19\par
20\par
21\par
22\par
23\par
24\par
25\par
26\par
27\par
28\par
29\par
30\par
31\par
32\par
33\par
34\par
35\par
36\par
37\par
38\par
39\par
40\par
41\par
# cp-access-log.sh\par
# This script downloads the file 'web-server-access-log.txt.gz'\par
# from "{{\field{\*\fldinst{HYPERLINK https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0250EN-SkillsNetwork/labs/Bash%20Scripting/ETL%20using%20shell%20scripting/ }}{\fldrslt{https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0250EN-SkillsNetwork/labs/Bash%20Scripting/ETL%20using%20shell%20scripting/\ul0\cf0}}}}\f0\fs32 ".\par
# The script then extracts the .txt file using gunzip.\par
# The .txt file contains the timestamp, latitude, longitude \par
# and visitor id apart from other data.\par
# Transforms the text delimeter from "#" to "," and saves to a csv file.\par
# Loads the data from the CSV file into the table 'access_log' in PostgreSQL database.\par
# Download the access log file\par
wget "{{\field{\*\fldinst{HYPERLINK https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0250EN-SkillsNetwork/labs/Bash%20Scripting/ETL%20using%20shell%20scripting/web-server-access-log.txt.gz }}{\fldrslt{https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0250EN-SkillsNetwork/labs/Bash%20Scripting/ETL%20using%20shell%20scripting/web-server-access-log.txt.gz\ul0\cf0}}}}\f0\fs32 "\par
# Unzip the file to extract the .txt file.\par
gunzip -f web-server-access-log.txt.gz\par
# Extract phase\par
echo "Extracting data"\par
# Extract the columns 1 (timestamp), 2 (latitude), 3 (longitude) and \par
# 4 (visitorid)\par
cut -d"#" -f1-4 web-server-access-log.txt > extracted-data.txt\par
# Transform phase\par
echo "Transforming data"\par
# read the extracted data and replace the colons with commas.\par
tr "#" "," < extracted-data.txt > transformed-data.csv\par
# Load phase\par
echo "Loading data"\par
# Send the instructions to connect to 'template1' and\par
# copy the file to the table 'access_log' through command pipeline.\par
echo "\\c template1;\\COPY access_log  FROM '/home/project/transformed-data.csv' DELIMITERS ',' CSV HEADER;" | psql --username=postgres --host=localhost\par
\par
Copied!\par
\par
Wrap Toggled!\par
Task 11. Verify by querying the database.\par
\par
Click here for Hint\par
Click here for Solution\par
Run the command below at Postgres SQL CLI prompt.\par
\par
1\par
SELECT * from access_log;\par
\par
Copied!\par
\par
Wrap Toggled!\par
You should see the records displayed on screen.\par
\par
}
 